{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10a82d67-73b5-4a43-affe-2dd8d1ebce09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:09:09.475 Python[78325:1067278] +[IMKClient subclass]: chose IMKClient_Legacy\n",
      "2024-10-23 16:09:09.475 Python[78325:1067278] +[IMKInputSession subclass]: chose IMKInputSession_Legacy\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the pre-trained MobileNet SSD model for vehicle detection\n",
    "net = cv2.dnn.readNetFromCaffe(\n",
    "    \"deploy.prototxt\", \n",
    "    \"mobilenet_iter_73000.caffemodel\"\n",
    ")\n",
    "\n",
    "# Set up video capture\n",
    "video_path = 'Cars Moving On Road Stock Footage - Free Download-2.mp4'  # Update the video path\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Parameters for Lucas-Kanade optical flow\n",
    "lk_params = dict(winSize=(15, 15), maxLevel=2,\n",
    "                 criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "\n",
    "# Parameters for Shi-Tomasi corner detection\n",
    "feature_params = dict(maxCorners=100, qualityLevel=0.3, minDistance=7, blockSize=7)\n",
    "\n",
    "# Conversion ratio from pixels to meters (adjust based on the actual video)\n",
    "pixels_per_meter = 10\n",
    "\n",
    "# Frame rate of the video\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "# Variable to hold the previous frame's grayscale image\n",
    "old_gray = None\n",
    "\n",
    "# Variable to hold the initial points for tracking\n",
    "p0 = None\n",
    "\n",
    "# List to store the estimated speeds\n",
    "speeds = []\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Prepare the frame for vehicle detection\n",
    "    (h, w) = frame.shape[:2]\n",
    "    blob = cv2.dnn.blobFromImage(cv2.resize(frame, (300, 300)), 0.007843, (300, 300), 127.5)\n",
    "    net.setInput(blob)\n",
    "    detections = net.forward()\n",
    "\n",
    "    # Convert the frame to grayscale for optical flow\n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    if old_gray is None:\n",
    "        # First frame: detect Shi-Tomasi corners\n",
    "        old_gray = frame_gray.copy()\n",
    "        p0 = cv2.goodFeaturesToTrack(old_gray, mask=None, **feature_params)\n",
    "\n",
    "        # Skip the rest of the loop to start tracking on the next frame\n",
    "        continue\n",
    "\n",
    "    # Calculate optical flow for the detected features\n",
    "    p1, st, err = cv2.calcOpticalFlowPyrLK(old_gray, frame_gray, p0, None, **lk_params)\n",
    "\n",
    "    # Select good points\n",
    "    good_new = p1[st == 1]\n",
    "    good_old = p0[st == 1]\n",
    "\n",
    "    # Calculate the average displacement and speed\n",
    "    if len(good_new) > 0:\n",
    "        displacement_pixels = np.linalg.norm(good_new - good_old, axis=1).mean()\n",
    "        displacement_meters = displacement_pixels / pixels_per_meter\n",
    "        speed_mps = displacement_meters * fps\n",
    "        speed_kmph = speed_mps * 3.6  # Convert to km/h\n",
    "\n",
    "        # Store the speed\n",
    "        speeds.append(speed_kmph)\n",
    "\n",
    "        # Draw the tracks\n",
    "        for i, (new, old) in enumerate(zip(good_new, good_old)):\n",
    "            a, b = map(int, new.ravel())\n",
    "            c, d = map(int, old.ravel())\n",
    "            frame = cv2.line(frame, (a, b), (c, d), (0, 255, 0), 2)\n",
    "            frame = cv2.circle(frame, (a, b), 5, (0, 0, 255), -1)\n",
    "\n",
    "        # Update previous frame and points\n",
    "        old_gray = frame_gray.copy()\n",
    "        p0 = good_new.reshape(-1, 1, 2)\n",
    "\n",
    "    # Display the frame with estimated speed\n",
    "    cv2.putText(frame, f'Speed: {speed_kmph:.2f} km/h', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    cv2.imshow(\"Speed Estimation\", frame)\n",
    "\n",
    "    # Exit on pressing 'q'\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6494165c-3801-46bb-b954-206482996781",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the pre-trained MobileNet SSD model for vehicle detection\n",
    "net = cv2.dnn.readNetFromCaffe(\n",
    "    \"deploy.prototxt\", \n",
    "    \"mobilenet_iter_73000.caffemodel\"\n",
    ")\n",
    "\n",
    "# Set up video capture\n",
    "video_path = 'Cars Moving On Road Stock Footage - Free Download-2.mp4'  # Update the video path to your local file\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# List of classes the MobileNet SSD can detect\n",
    "CLASSES = [\"background\", \"aeroplane\", \"bicycle\", \"bird\", \"boat\",\n",
    "           \"bottle\", \"bus\", \"car\", \"cat\", \"chair\", \"cow\", \"diningtable\",\n",
    "           \"dog\", \"horse\", \"motorbike\", \"person\", \"pottedplant\",\n",
    "           \"sheep\", \"sofa\", \"train\", \"tvmonitor\"]\n",
    "\n",
    "# Set the confidence threshold for detecting vehicles\n",
    "CONFIDENCE_THRESHOLD = 0.5\n",
    "\n",
    "# Delay to slow down the video (in milliseconds)\n",
    "slow_down_delay = 100  # Adjust this value to slow down the video\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Prepare the frame for vehicle detection\n",
    "    (h, w) = frame.shape[:2]\n",
    "    blob = cv2.dnn.blobFromImage(cv2.resize(frame, (300, 300)), 0.007843, (300, 300), 127.5)\n",
    "    net.setInput(blob)\n",
    "    detections = net.forward()\n",
    "\n",
    "    # Loop over the detections\n",
    "    for i in np.arange(0, detections.shape[2]):\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "\n",
    "        # Filter out weak detections\n",
    "        if confidence > CONFIDENCE_THRESHOLD:\n",
    "            # Get the class label index\n",
    "            idx = int(detections[0, 0, i, 1])\n",
    "\n",
    "            # Only proceed if the detected object is a car (class label 'car')\n",
    "            if CLASSES[idx] == \"car\":\n",
    "                # Get the bounding box coordinates\n",
    "                box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "                (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "\n",
    "                # Draw the bounding box and label on the frame\n",
    "                label = f\"{CLASSES[idx]}: {confidence * 100:.2f}%\"\n",
    "                cv2.rectangle(frame, (startX, startY), (endX, endY), (0, 255, 0), 2)\n",
    "                cv2.putText(frame, label, (startX, startY - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "    # Display the output frame\n",
    "    cv2.imshow(\"Vehicle Detection\", frame)\n",
    "\n",
    "    # Slow down the video by increasing the waitKey delay\n",
    "    if cv2.waitKey(slow_down_delay) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fb65a61-6353-4e4e-953b-80b574393436",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the pre-trained MobileNet SSD model for vehicle detection\n",
    "net = cv2.dnn.readNetFromCaffe(\n",
    "    \"deploy.prototxt\", \n",
    "    \"mobilenet_iter_73000.caffemodel\"\n",
    ")\n",
    "\n",
    "# Set up video capture\n",
    "video_path = 'Cars Moving On Road Stock Footage - Free Download-2.mp4'  # Update the video path to your local file\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# List of classes the MobileNet SSD can detect\n",
    "CLASSES = [\"background\", \"aeroplane\", \"bicycle\", \"bird\", \"boat\",\n",
    "           \"bottle\", \"bus\", \"car\", \"cat\", \"chair\", \"cow\", \"diningtable\",\n",
    "           \"dog\", \"horse\", \"motorbike\", \"person\", \"pottedplant\",\n",
    "           \"sheep\", \"sofa\", \"train\", \"tvmonitor\"]\n",
    "\n",
    "# Set the confidence threshold for detecting vehicles\n",
    "CONFIDENCE_THRESHOLD = 0.5\n",
    "\n",
    "# Conversion factor for pixels to meters (example value, adjust based on your video)\n",
    "pixels_per_meter = 10\n",
    "\n",
    "# Frame rate of the video\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "# Dictionary to keep track of vehicle positions across frames\n",
    "tracked_vehicles = {}\n",
    "\n",
    "# Vehicle ID counter\n",
    "vehicle_id_counter = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Prepare the frame for vehicle detection\n",
    "    (h, w) = frame.shape[:2]\n",
    "    blob = cv2.dnn.blobFromImage(cv2.resize(frame, (300, 300)), 0.007843, (300, 300), 127.5)\n",
    "    net.setInput(blob)\n",
    "    detections = net.forward()\n",
    "\n",
    "    # Temporary dictionary for this frame's vehicle positions\n",
    "    current_frame_vehicles = {}\n",
    "\n",
    "    # Loop over the detections\n",
    "    for i in np.arange(0, detections.shape[2]):\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "\n",
    "        # Filter out weak detections\n",
    "        if confidence > CONFIDENCE_THRESHOLD:\n",
    "            # Get the class label index\n",
    "            idx = int(detections[0, 0, i, 1])\n",
    "\n",
    "            # Only proceed if the detected object is a car (class label 'car')\n",
    "            if CLASSES[idx] == \"car\":\n",
    "                # Get the bounding box coordinates\n",
    "                box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "                (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "\n",
    "                # Compute the center of the bounding box\n",
    "                centerX = int((startX + endX) / 2)\n",
    "                centerY = int((startY + endY) / 2)\n",
    "\n",
    "                # Try to match this detection with an existing tracked vehicle\n",
    "                matched_vehicle_id = None\n",
    "                for vehicle_id, prev_position in tracked_vehicles.items():\n",
    "                    prev_centerX, prev_centerY = prev_position\n",
    "                    distance = np.sqrt((centerX - prev_centerX) ** 2 + (centerY - prev_centerY) ** 2)\n",
    "                    if distance < 50:  # Threshold to match the same vehicle\n",
    "                        matched_vehicle_id = vehicle_id\n",
    "                        break\n",
    "\n",
    "                # If no match, assign a new vehicle ID\n",
    "                if matched_vehicle_id is None:\n",
    "                    matched_vehicle_id = vehicle_id_counter\n",
    "                    vehicle_id_counter += 1\n",
    "\n",
    "                # Update current frame vehicle positions\n",
    "                current_frame_vehicles[matched_vehicle_id] = (centerX, centerY)\n",
    "\n",
    "                # Measure the speed if the vehicle was previously tracked\n",
    "                if matched_vehicle_id in tracked_vehicles:\n",
    "                    prev_centerX, prev_centerY = tracked_vehicles[matched_vehicle_id]\n",
    "                    displacement_pixels = np.sqrt((centerX - prev_centerX) ** 2 + (centerY - prev_centerY) ** 2)\n",
    "                    displacement_meters = displacement_pixels / pixels_per_meter\n",
    "                    speed_mps = displacement_meters * fps\n",
    "                    speed_kmph = speed_mps * 3.6  # Convert to km/h\n",
    "\n",
    "                    # Draw the speed and bounding box on the frame\n",
    "                    label = f\"ID {matched_vehicle_id} Speed: {speed_kmph:.2f} km/h\"\n",
    "                    cv2.rectangle(frame, (startX, startY), (endX, endY), (0, 255, 0), 2)\n",
    "                    cv2.putText(frame, label, (startX, startY - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "    # Update the tracked vehicles with current frame positions\n",
    "    tracked_vehicles = current_frame_vehicles\n",
    "\n",
    "    # Display the output frame\n",
    "    cv2.imshow(\"Vehicle Detection and Speed Estimation\", frame)\n",
    "\n",
    "    # Exit on 'q' key press\n",
    "    if cv2.waitKey(100) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8e68b85-1b41-43f5-9ce5-c375d08da3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "from collections import deque\n",
    "\n",
    "# Load the Caffe model\n",
    "net = cv2.dnn.readNetFromCaffe(\"deploy.prototxt\", \"mobilenet_iter_73000.caffemodel\")\n",
    "\n",
    "# Initialize video capture\n",
    "video_path = 'Cars Moving On Road Stock Footage - Free Download-2.mp4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "scale_factor = 10  # Example scale factor for pixel-to-meter conversion (adjust based on calibration)\n",
    "\n",
    "# Function to estimate speed\n",
    "def calculate_speed(pixel_distance, scale_factor, frame_rate):\n",
    "    # Convert pixel displacement to meters\n",
    "    real_world_distance = pixel_distance / scale_factor\n",
    "    # Speed in meters per second\n",
    "    speed_mps = real_world_distance * frame_rate\n",
    "    # Convert to kilometers per hour\n",
    "    speed_kph = speed_mps * 3.6\n",
    "    return speed_kph\n",
    "\n",
    "# Vehicle tracking\n",
    "tracker = {}\n",
    "track_history = deque(maxlen=5)  # Store last 5 positions for each tracked object\n",
    "\n",
    "# Process each frame from the video\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Prepare the frame for object detection\n",
    "    h, w = frame.shape[:2]\n",
    "    blob = cv2.dnn.blobFromImage(frame, scalefactor=0.007843, size=(300, 300), mean=(127.5, 127.5, 127.5))\n",
    "    net.setInput(blob)\n",
    "\n",
    "    # Perform object detection\n",
    "    detections = net.forward()\n",
    "\n",
    "    # Track detected vehicles using centroids\n",
    "    current_centroids = []\n",
    "    for i in range(detections.shape[2]):\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "        if confidence > 0.5:\n",
    "            class_id = int(detections[0, 0, i, 1])\n",
    "            # Filter for vehicles: assuming class IDs correspond to car-related classes in your model\n",
    "            if class_id == 7:  # Example: COCO class ID for car\n",
    "                # Get bounding box coordinates\n",
    "                box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "                (x1, y1, x2, y2) = box.astype(\"int\")\n",
    "                centroid = ((x1 + x2) // 2, (y1 + y2) // 2)\n",
    "                current_centroids.append(centroid)\n",
    "\n",
    "                # Draw the bounding box\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                cv2.putText(frame, f'Confidence: {confidence:.2f}', (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "    # Update tracker and calculate speed\n",
    "    for i, centroid in enumerate(current_centroids):\n",
    "        if i not in tracker:\n",
    "            tracker[i] = centroid\n",
    "            track_history.append((i, centroid))\n",
    "        else:\n",
    "            previous_centroid = tracker[i]\n",
    "            pixel_distance = np.linalg.norm(np.array(centroid) - np.array(previous_centroid))\n",
    "\n",
    "            # Estimate speed\n",
    "            speed_kph = calculate_speed(pixel_distance, scale_factor, fps)\n",
    "            cv2.putText(frame, f'Speed: {speed_kph:.2f} km/h', (centroid[0], centroid[1] - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.75, (255, 0, 0), 2)\n",
    "\n",
    "            # Update tracker\n",
    "            tracker[i] = centroid\n",
    "            track_history.append((i, centroid))\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow('Vehicle Detection and Speed Estimation', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c769eadd-58f3-44e2-b6ae-12788d50caef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-21 21:52:56.039 Python[75779:808207] +[IMKClient subclass]: chose IMKClient_Legacy\n",
      "2024-10-21 21:52:56.039 Python[75779:808207] +[IMKInputSession subclass]: chose IMKInputSession_Legacy\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "\n",
    "# Load the Caffe model\n",
    "net = cv2.dnn.readNetFromCaffe(\"deploy.prototxt\", \"mobilenet_iter_73000.caffemodel\")\n",
    "\n",
    "# Initialize video capture\n",
    "video_path = 'Cars Moving On Road Stock Footage - Free Download-2.mp4'  # Change to the path of your video file\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "# Set a scale factor for pixel-to-meter conversion\n",
    "# Example: 50 pixels correspond to 5 meters => scale_factor = 50 / 5 = 10 pixels per meter\n",
    "scale_factor = 10.0  # Adjust this based on your calibration\n",
    "\n",
    "# Function to estimate speed\n",
    "def calculate_speed(pixel_distance, scale_factor, frame_rate):\n",
    "    # Convert pixel displacement to meters\n",
    "    real_world_distance = pixel_distance / scale_factor\n",
    "    # Speed in meters per second\n",
    "    speed_mps = real_world_distance * frame_rate\n",
    "    # Convert to kilometers per hour\n",
    "    speed_kph = speed_mps * 3.6\n",
    "    return speed_kph\n",
    "\n",
    "# Function to smooth the speed estimates\n",
    "def smoothed_speed(new_speed, speed_history):\n",
    "    speed_history.append(new_speed)\n",
    "    return sum(speed_history) / len(speed_history)\n",
    "\n",
    "# Vehicle tracking\n",
    "tracker = {}\n",
    "speed_history = deque(maxlen=5)  # Keep the last 5 speed measurements\n",
    "\n",
    "# Process each frame from the video\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Prepare the frame for object detection\n",
    "    h, w = frame.shape[:2]\n",
    "    blob = cv2.dnn.blobFromImage(frame, scalefactor=0.007843, size=(300, 300), mean=(127.5, 127.5, 127.5))\n",
    "    net.setInput(blob)\n",
    "\n",
    "    # Perform object detection\n",
    "    detections = net.forward()\n",
    "\n",
    "    # Track detected vehicles using centroids\n",
    "    current_centroids = []\n",
    "    for i in range(detections.shape[2]):\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "        if confidence > 0.5:\n",
    "            class_id = int(detections[0, 0, i, 1])\n",
    "            # Assuming class ID 7 corresponds to a car (check your model's labels)\n",
    "            if class_id == 7:\n",
    "                # Get bounding box coordinates\n",
    "                box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "                (x1, y1, x2, y2) = box.astype(\"int\")\n",
    "                centroid = ((x1 + x2) // 2, (y1 + y2) // 2)\n",
    "                current_centroids.append(centroid)\n",
    "\n",
    "                # Draw the bounding box\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                cv2.putText(frame, f'Confidence: {confidence:.2f}', (x1, y1 - 10), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "    # Update tracker and calculate speed\n",
    "    for i, centroid in enumerate(current_centroids):\n",
    "        if i not in tracker:\n",
    "            tracker[i] = centroid\n",
    "        else:\n",
    "            previous_centroid = tracker[i]\n",
    "            pixel_distance = np.linalg.norm(np.array(centroid) - np.array(previous_centroid))\n",
    "\n",
    "            # Estimate speed\n",
    "            speed_kph = calculate_speed(pixel_distance, scale_factor, fps)\n",
    "\n",
    "            # Apply smoothing to reduce variability\n",
    "            smoothed_speed_kph = smoothed_speed(speed_kph, speed_history)\n",
    "\n",
    "            # Display the smoothed speed\n",
    "            cv2.putText(frame, f'Speed: {smoothed_speed_kph:.2f} km/h', (centroid[0], centroid[1] - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.75, (255, 0, 0), 2)\n",
    "\n",
    "            # Update tracker\n",
    "            tracker[i] = centroid\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow('Vehicle Detection and Speed Estimation', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca5505c0-9624-4f74-8227-948f9ebf9cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "\n",
    "# Load the Caffe model\n",
    "net = cv2.dnn.readNetFromCaffe(\"deploy.prototxt\", \"mobilenet_iter_73000.caffemodel\")\n",
    "\n",
    "# Use the uploaded video file\n",
    "video_path = 'Cars Moving On Road Stock Footage - Free Download-2.mp4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "# Set a scale factor for pixel-to-meter conversion\n",
    "# The scale_factor needs calibration based on a known distance in the video\n",
    "scale_factor = 33.33  # Adjust this based on your calibration\n",
    "\n",
    "# Function to estimate speed\n",
    "def calculate_speed(pixel_distance, scale_factor, frame_rate):\n",
    "    real_world_distance = pixel_distance / scale_factor\n",
    "    speed_mps = real_world_distance * frame_rate\n",
    "    speed_kph = speed_mps * 3.6\n",
    "    return speed_kph\n",
    "\n",
    "# Function to smooth the speed estimates\n",
    "def smoothed_speed(new_speed, speed_history):\n",
    "    speed_history.append(new_speed)\n",
    "    return sum(speed_history) / len(speed_history)\n",
    "\n",
    "# Vehicle tracking\n",
    "tracker = {}\n",
    "speed_history = deque(maxlen=5)  # Keep the last 5 speed measurements\n",
    "\n",
    "# Process each frame from the video\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Prepare the frame for object detection\n",
    "    h, w = frame.shape[:2]\n",
    "    blob = cv2.dnn.blobFromImage(frame, scalefactor=0.007843, size=(300, 300), mean=(127.5, 127.5, 127.5))\n",
    "    net.setInput(blob)\n",
    "\n",
    "    # Perform object detection\n",
    "    detections = net.forward()\n",
    "\n",
    "    # Track detected vehicles using centroids\n",
    "    current_centroids = []\n",
    "    for i in range(detections.shape[2]):\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "        if confidence > 0.5:\n",
    "            class_id = int(detections[0, 0, i, 1])\n",
    "            # Assuming class ID 7 corresponds to a car\n",
    "            if class_id == 7:\n",
    "                # Get bounding box coordinates\n",
    "                box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "                (x1, y1, x2, y2) = box.astype(\"int\")\n",
    "                centroid = ((x1 + x2) // 2, (y1 + y2) // 2)\n",
    "                current_centroids.append(centroid)\n",
    "\n",
    "                # Draw the bounding box\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                cv2.putText(frame, f'Confidence: {confidence:.2f}', (x1, y1 - 10), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "    # Update tracker and calculate speed\n",
    "    for i, centroid in enumerate(current_centroids):\n",
    "        if i not in tracker:\n",
    "            tracker[i] = centroid\n",
    "        else:\n",
    "            previous_centroid = tracker[i]\n",
    "            pixel_distance = np.linalg.norm(np.array(centroid) - np.array(previous_centroid))\n",
    "\n",
    "            # Estimate speed\n",
    "            speed_kph = calculate_speed(pixel_distance, scale_factor, fps)\n",
    "\n",
    "            # Apply smoothing to reduce variability\n",
    "            smoothed_speed_kph = smoothed_speed(speed_kph, speed_history)\n",
    "\n",
    "            # Display the smoothed speed\n",
    "            cv2.putText(frame, f'Speed: {smoothed_speed_kph:.2f} km/h', (centroid[0], centroid[1] - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.75, (255, 0, 0), 2)\n",
    "\n",
    "            # Update tracker\n",
    "            tracker[i] = centroid\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow('Vehicle Detection and Speed Estimation', frame)\n",
    "    if cv2.waitKey(50) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88ac9056-1476-4ea7-abac-17edec47451b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 15:54:37.292 Python[78280:1064755] +[IMKClient subclass]: chose IMKClient_Legacy\n",
      "2024-10-23 15:54:37.292 Python[78280:1064755] +[IMKInputSession subclass]: chose IMKInputSession_Legacy\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "\n",
    "# Load the Caffe model\n",
    "net = cv2.dnn.readNetFromCaffe(\"deploy.prototxt\", \"mobilenet_iter_73000.caffemodel\")\n",
    "\n",
    "# Use the uploaded video file\n",
    "video_path = 'Cars Moving On Road Stock Footage - Free Download-2.mp4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "# Estimated scale factor based on an average car length of 4.5 meters and approximately 150 pixels\n",
    "scale_factor = 33.33  # Pixels per meter\n",
    "\n",
    "# Define the y-coordinate of the target line where speed will be shown\n",
    "target_line_y = 400  # Adjust this value based on the position in the frame\n",
    "\n",
    "# Function to estimate speed\n",
    "def calculate_speed(pixel_distance, scale_factor, frame_rate):\n",
    "    real_world_distance = pixel_distance / scale_factor\n",
    "    speed_mps = real_world_distance * frame_rate\n",
    "    speed_kph = speed_mps * 3.6\n",
    "    return speed_kph\n",
    "\n",
    "# Function to smooth the speed estimates\n",
    "def smoothed_speed(new_speed, speed_history):\n",
    "    speed_history.append(new_speed)\n",
    "    return sum(speed_history) / len(speed_history)\n",
    "\n",
    "# Vehicle tracking\n",
    "tracker = {}\n",
    "speed_history = deque(maxlen=5)  # Keep the last 5 speed measurements\n",
    "\n",
    "# Process each frame from the video\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Draw the target line\n",
    "    cv2.line(frame, (0, target_line_y), (frame.shape[1], target_line_y), (0, 0, 255), 2)\n",
    "\n",
    "    # Prepare the frame for object detection\n",
    "    h, w = frame.shape[:2]\n",
    "    blob = cv2.dnn.blobFromImage(frame, scalefactor=0.007843, size=(300, 300), mean=(127.5, 127.5, 127.5))\n",
    "    net.setInput(blob)\n",
    "\n",
    "    # Perform object detection\n",
    "    detections = net.forward()\n",
    "\n",
    "    # Track detected vehicles using centroids\n",
    "    current_centroids = []\n",
    "    for i in range(detections.shape[2]):\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "        if confidence > 0.5:\n",
    "            class_id = int(detections[0, 0, i, 1])\n",
    "            # Assuming class ID 7 corresponds to a car\n",
    "            if class_id == 7:\n",
    "                # Get bounding box coordinates\n",
    "                box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "                (x1, y1, x2, y2) = box.astype(\"int\")\n",
    "                centroid = ((x1 + x2) // 2, (y1 + y2) // 2)\n",
    "                current_centroids.append((i, centroid))  # Store the index and centroid\n",
    "\n",
    "                # Draw the bounding box\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                cv2.putText(frame, f'Confidence: {confidence:.2f}', (x1, y1 - 10), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "    # Update tracker and calculate speed\n",
    "    for i, centroid in current_centroids:\n",
    "        if i not in tracker:\n",
    "            tracker[i] = centroid\n",
    "        else:\n",
    "            previous_centroid = tracker[i]\n",
    "            pixel_distance = np.linalg.norm(np.array(centroid) - np.array(previous_centroid))\n",
    "\n",
    "            # Estimate speed\n",
    "            speed_kph = calculate_speed(pixel_distance, scale_factor, fps)\n",
    "\n",
    "            # Apply smoothing to reduce variability\n",
    "            smoothed_speed_kph = smoothed_speed(speed_kph, speed_history)\n",
    "\n",
    "            # Display the speed only if the centroid crosses the target line\n",
    "            if previous_centroid[1] < target_line_y <= centroid[1]:\n",
    "                cv2.putText(frame, f'Speed: {smoothed_speed_kph:.2f} km/h', (centroid[0], centroid[1] - 10),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.75, (255, 0, 0), 2)\n",
    "\n",
    "            # Update tracker\n",
    "            tracker[i] = centroid\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow('Vehicle Detection and Speed Estimation', frame)\n",
    "    if cv2.waitKey(50) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabfef04-b3b0-428b-972a-3395e062f6d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
